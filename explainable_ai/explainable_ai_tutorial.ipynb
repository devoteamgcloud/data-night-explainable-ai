{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d9edb6-92a9-40bb-9e41-7ee3c8894609",
   "metadata": {},
   "source": [
    "# Hello ML engineers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6e9c9-4352-4be1-9805-931f1a6ac919",
   "metadata": {},
   "source": [
    "In this small tutorial, we will learn to build an AutoML model to perform a regression on the *House Prices* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a3db0-8235-4bdd-830d-b601ce16d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e4e21-5134-42a7-86ca-12e417b9cae5",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ceb86-62d0-4552-aefb-875ae1dfcdf6",
   "metadata": {},
   "source": [
    "- `PROJECT_ID` is something you can find in the Google Cloud Console, by going to the menu -> Cloud Overview -> Dashboard.\n",
    "- `LOCATION` is up to your choice, but since your BigQuery dataset is in Europe, you would probably like your models and versionized dataset to be located in Europe as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a802f2-a70a-460a-86cc-242e6d24ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: adapt the following variables\n",
    "PROJECT_ID = ...\n",
    "LOCATION = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb324103-cf31-44a7-b76c-6ffdc5b98211",
   "metadata": {},
   "source": [
    "Under, we initialize the Vertex AI SDK to work in the correct project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6987d25-41a1-4cf4-ba0e-5334af64c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec88fa7-8298-41dc-a206-874f65e52213",
   "metadata": {},
   "source": [
    "## Create a tabular dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b24fc4-e192-4804-b769-f52a322a5020",
   "metadata": {},
   "source": [
    "Choose a BigQuery source for your dataset. The format should be `bq://{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d95fd5-38d5-46c9-9d41-a92d40ebd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: adapt the following variables\n",
    "BQ_SOURCE = ...\n",
    "DATASET_DISPLAY_NAME = \"my-small-dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176360a-5839-48ae-9485-090ba25db16a",
   "metadata": {},
   "source": [
    "If you do not wish to use the dataset you created during the data part, feel free to use the following source:\n",
    "`bq://data-night-2023-bigquery.ML_house_prices.training_set`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47617aa-3890-4d18-9027-97e3a603d951",
   "metadata": {},
   "source": [
    "Then, you need to create the tabular dataset using the Vertex AI SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa38c0e-c667-4bab-99e3-9c51893130ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: create a tabular dataset\n",
    "# clue: https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/overview\n",
    "dataset = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b69e5f-0cd7-4e53-842d-c3c583c112b2",
   "metadata": {},
   "source": [
    "And wait for the job to complete..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8fc19-57f5-408d-b537-6cabe9f81124",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.wait()\n",
    "\n",
    "print(f'\\tDataset: \"{dataset.display_name}\"')\n",
    "print(f'\\tname: \"{dataset.resource_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead85a51-d96f-4384-a8f1-3690879f5f44",
   "metadata": {},
   "source": [
    "## Create an AutoML training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59130a8-75d4-4932-81ab-fb09fa37ef63",
   "metadata": {},
   "source": [
    "Now, you need to adapt the variable to create an AutoML training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c14fb-4788-416c-b3b5-6a92ec71180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: adapt the following variables\n",
    "TRAINING_JOB_DISPLAY_NAME = \"my-small-training-job\"\n",
    "TARGET_COLUMN = ...\n",
    "OPTIMIZATION_PREDICTION_TYPE = \"regression\"\n",
    "OPTIMIZATION_OBJECTIVE = ...\n",
    "TRAINING_FRACTION_SPLIT = ...\n",
    "VALIDATION_FRACTION_SPLIT = (1.0 - TRAINING_FRACTION_SPLIT) / 2.0\n",
    "TEST_FRACTION_SPLIT = VALIDATION_FRACTION_SPLIT\n",
    "BUDGET_MILLI_NODE_HOURS = 1000 # one hour\n",
    "MODEL_DISPLAY_NAME = \"my-small-model\"\n",
    "DISABLE_EARLY_STOPPING = False\n",
    "SYNC = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6084a2-1406-4e7c-ad59-160f609b1d52",
   "metadata": {},
   "source": [
    "And finally, create the AutoML training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c609d-9f45-4c6b-91ee-be48b54b5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: create an AutoML training job\n",
    "# clue: https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/overview\n",
    "tabular_regression_job = ...\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39dc81-065a-40b0-8e09-b86a06501fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6437247-a728-4240-bb8b-d1d4501fc722",
   "metadata": {},
   "source": [
    "## (Partial) congrats!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c01a85-edc1-4499-a822-6ad34acfeb9a",
   "metadata": {},
   "source": [
    "You have successfully trained your model! Maybe without even looking at the documentation? ;-)\n",
    "The training will continue for quite some time. To speed things up, we will use a pre-trained model for the next part.\n",
    "\n",
    "Be sure to **stop the training**, otherwise you won't be able to run the next steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b5e7f-d3b0-4138-a9d3-14617738b643",
   "metadata": {},
   "source": [
    "Now, will you be able to generate explainable predictions? Let's see... MWAH AH AH AH AH!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5b23f-379a-40b7-91a6-f224612b08a3",
   "metadata": {},
   "source": [
    "## Generate explainable predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ff484-bb3e-4e8e-a81c-8028097942fb",
   "metadata": {},
   "source": [
    "The model that we will use in this section is deployed to an endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3db82-a81a-4304-86b4-f429a4499b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_id = \"projects/data-night-2023-bigquery/locations/europe-west1/endpoints/6646099189161787392\"\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b96e56-def4-401e-af9d-82a92b80a85e",
   "metadata": {},
   "source": [
    "Let's retrieve the validation set from BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807b19f-521e-4770-aedf-986def22f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "df = bigquery_client.query(\"\"\"\n",
    "    SELECT * FROM\n",
    "    `data-night-2023-bigquery.ML_house_prices.validation_set`\n",
    "\"\"\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a2927-5fe3-4d19-a494-7205aa831355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71779593-26a4-45fa-900c-60d7a670a322",
   "metadata": {},
   "source": [
    "We will only use one row from the hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fa86f-b584-4307-8eb2-51f00a8c758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.sample()\n",
    "row = row.drop(\"SalesPrice\", axis=1)\n",
    "for column in row.columns:\n",
    "    row[column] = row[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b49888-a32f-47cb-af6b-75f6f2d75f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: create an instance dict\n",
    "# it complies with the following schema:\n",
    "# [{\"COLUMN_A\": VALUE_A, \"COLUMN_B\": VALUE_B, ..., \"COLUMN_Z\": VALUE_Z}]\n",
    "instance_dict = [{...}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a9a3b-c5b4-4fbd-b999-621e2de6d4fa",
   "metadata": {},
   "source": [
    "Let's generate explanations for the row we have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198eee0-c174-464d-a3d2-99088107b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = endpoint.explain(instances=instance_dict, parameters={})\n",
    "\n",
    "for explanation in response.explanations:\n",
    "    attributions = explanation.attributions\n",
    "    for attribution in attributions:\n",
    "        print(\"  attribution\")\n",
    "        print(\"   baseline_output_value:\", attribution.baseline_output_value)\n",
    "        print(\"   instance_output_value:\", attribution.instance_output_value)\n",
    "        print(\"   approximation_error:\", attribution.approximation_error)\n",
    "\n",
    "feature_attributions = pd.Series(dict(attribution.feature_attributions))\n",
    "\n",
    "for column in feature_attributions.index:\n",
    "    feature_attributions[f\"{column} ({row.iloc[0].at[column]})\"] = feature_attributions[column]\n",
    "    feature_attributions = feature_attributions.drop(column)\n",
    "\n",
    "IMPORTANCE_THRESHOLD = 181_085.181 * 0.01\n",
    "feature_attributions = feature_attributions[abs(feature_attributions) > IMPORTANCE_THRESHOLD].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d691929-053b-48ae-8560-e333816ef497",
   "metadata": {},
   "source": [
    "We can plot the feature attributions to check how each individual feature influences the prediction positively or negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ca697-5534-4155-a287-d17c2c2268a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_attributions.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f9e40-8499-42a1-914c-6f39ebc3b73c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53452267-648d-4d5d-9437-f4d633ae16d4",
   "metadata": {},
   "source": [
    "Congrats! You have now completed this tutorial. Thanks to Google Cloud, you were able to create an AutoML model to perform regression on the House Prices dataset. You were then able to activate the explainable predictions from the model and understood what feature attributions were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f7bf-ac56-4e45-8396-5841c7e5a83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
